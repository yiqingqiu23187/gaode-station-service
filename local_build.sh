#!/bin/bash

# é«˜å¾·åœ°å›¾æœåŠ¡ç«™ç‚¹æŸ¥è¯¢å·¥å…· - æœ¬åœ°æž„å»ºè„šæœ¬
# åŠŸèƒ½ï¼šæ•°æ®å¤„ç†ã€Dockeré•œåƒæž„å»ºå’Œæ‰“åŒ…

set -e  # é‡åˆ°é”™è¯¯ç«‹å³é€€å‡º

# === é…ç½®ä¿¡æ¯ ===
IMAGE_NAME="gaode-station-service"
IMAGE_TAG="latest"
IMAGE_TAR="${IMAGE_NAME}-${IMAGE_TAG}.tar"
COMPOSE_FILE="docker-compose.prod.yml"
BUILD_INFO_FILE="build_info.json"

# é¢œè‰²è¾“å‡º
GREEN='\033[0;32m'
RED='\033[0;31m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

log_info() {
    echo -e "${GREEN}[INFO]${NC} $1"
}

log_warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

log_error() {
    echo -e "${RED}[ERROR]${NC} $1"
}

log_step() {
    echo -e "${BLUE}[STEP]${NC} $1"
}

# === æ­¥éª¤1ï¼šæ£€æŸ¥æœ¬åœ°çŽ¯å¢ƒ ===
check_local_environment() {
    log_step "æ£€æŸ¥æœ¬åœ°çŽ¯å¢ƒ..."

    # æ£€æŸ¥Docker
    if ! command -v docker &> /dev/null; then
        log_error "Docker æœªå®‰è£…ï¼Œè¯·å…ˆå®‰è£… Docker"
        exit 1
    fi

    # æ£€æŸ¥Dockeræ˜¯å¦è¿è¡Œ
    if ! docker info &> /dev/null; then
        log_error "Docker æœªè¿è¡Œï¼Œè¯·å¯åŠ¨ Docker"
        exit 1
    fi

    # æ£€æŸ¥Python
    if ! command -v python3 &> /dev/null; then
        log_error "Python3 æœªå®‰è£…"
        exit 1
    fi

    # æ£€æŸ¥å¸¦åæ ‡çš„CSVæ–‡ä»¶
    COORDS_CSV="å²—ä½ä½ç½®ä¿¡æ¯åº•è¡¨_with_coords.csv"
    if [ ! -f "$COORDS_CSV" ]; then
        log_error "æœªæ‰¾åˆ°å¸¦åæ ‡çš„CSVæ–‡ä»¶: $COORDS_CSV"
        exit 1
    fi

    # æ£€æŸ¥å¿…è¦æ–‡ä»¶
    for file in "Dockerfile" "requirements.txt" "database_setup.py"; do
        if [ ! -f "$file" ]; then
            log_error "æœªæ‰¾åˆ°å¿…è¦æ–‡ä»¶: $file"
            exit 1
        fi
    done

    log_info "æœ¬åœ°çŽ¯å¢ƒæ£€æŸ¥å®Œæˆ âœ“"
}

# === æ­¥éª¤2ï¼šå¤„ç†æœ¬åœ°æ•°æ® ===
process_local_data() {
    log_step "å¤„ç†æœ¬åœ°æ•°æ®..."

    # åˆ›å»ºè™šæ‹ŸçŽ¯å¢ƒï¼ˆç”¨äºŽæ•°æ®å¤„ç†ï¼‰
    if [ ! -d ".venv" ]; then
        log_info "åˆ›å»ºè™šæ‹ŸçŽ¯å¢ƒ..."
        python3 -m venv .venv

        if [ -f "requirements.txt" ]; then
            log_info "å®‰è£…Pythonä¾èµ–..."
            .venv/bin/pip install --upgrade pip --quiet
            .venv/bin/pip install -r requirements.txt --quiet
        fi
    fi

    # æ¿€æ´»è™šæ‹ŸçŽ¯å¢ƒå¹¶å¤„ç†æ•°æ®
    source .venv/bin/activate

    # æ£€æŸ¥çŽ°æœ‰æ•°æ®åº“æ˜¯å¦åŒ…å«å®Œæ•´æ•°æ®
    if [ -f "stations.db" ]; then
        log_info "æ£€æŸ¥çŽ°æœ‰æ•°æ®åº“..."

        # æ£€æŸ¥æ•°æ®åº“ä¸­çš„å²—ä½æ•°é‡
        JOB_COUNT=$(python3 -c "
import sqlite3
try:
    conn = sqlite3.connect('stations.db')
    cursor = conn.cursor()
    cursor.execute('SELECT COUNT(*) FROM job_positions')
    count = cursor.fetchone()[0]
    conn.close()
    print(count)
except:
    print(0)
" 2>/dev/null || echo "0")

        # æ£€æŸ¥æ˜¯å¦æœ‰åŒ—äº¬æ•°æ®
        BEIJING_COUNT=$(python3 -c "
import sqlite3
try:
    conn = sqlite3.connect('stations.db')
    cursor = conn.cursor()
    cursor.execute('SELECT COUNT(*) FROM job_positions WHERE city = \"åŒ—äº¬\"')
    count = cursor.fetchone()[0]
    conn.close()
    print(count)
except:
    print(0)
" 2>/dev/null || echo "0")

        # æ£€æŸ¥æ˜¯å¦æœ‰å¤–å–æ•°æ®
        WAIMAI_COUNT=$(python3 -c "
import sqlite3
try:
    conn = sqlite3.connect('stations.db')
    cursor = conn.cursor()
    cursor.execute('SELECT COUNT(*) FROM job_positions WHERE job_type = \"ç¾Žå›¢å¤–å–éª‘æ‰‹\"')
    count = cursor.fetchone()[0]
    conn.close()
    print(count)
except:
    print(0)
" 2>/dev/null || echo "0")

        log_info "çŽ°æœ‰æ•°æ®åº“ç»Ÿè®¡: æ€»å²—ä½${JOB_COUNT}ä¸ª, åŒ—äº¬${BEIJING_COUNT}ä¸ª, å¤–å–${WAIMAI_COUNT}ä¸ª"

        # å¦‚æžœæ•°æ®åº“åŒ…å«å®Œæ•´æ•°æ®ï¼ˆ>1000ä¸ªå²—ä½ï¼ŒåŒ…å«åŒ—äº¬å’Œå¤–å–æ•°æ®ï¼‰ï¼Œåˆ™è·³è¿‡é‡å»º
        if [ "$JOB_COUNT" -gt 1000 ] && [ "$BEIJING_COUNT" -gt 500 ] && [ "$WAIMAI_COUNT" -gt 70 ]; then
            log_info "æ£€æµ‹åˆ°å®Œæ•´æ•°æ®åº“ï¼Œè·³è¿‡é‡å»ºï¼Œç›´æŽ¥ä½¿ç”¨çŽ°æœ‰æ•°æ®åº“ âœ“"
            deactivate
            log_info "æœ¬åœ°æ•°æ®å¤„ç†å®Œæˆ âœ“"
            return
        else
            log_warning "æ•°æ®åº“ä¸å®Œæ•´ï¼Œå°†é‡æ–°åˆ›å»º"
            # å¤‡ä»½æ—§çš„æ•°æ®åº“æ–‡ä»¶
            cp stations.db "stations.db.backup.$(date +%Y%m%d_%H%M%S)"
            log_info "å·²å¤‡ä»½çŽ°æœ‰æ•°æ®åº“æ–‡ä»¶"
        fi
    fi

    # åˆ›å»ºæ•°æ®åº“
    log_info "æ­£åœ¨åˆ›å»ºSQLiteæ•°æ®åº“..."
    python database_setup.py

    if [ ! -f "stations.db" ]; then
        log_error "æ•°æ®åº“åˆ›å»ºå¤±è´¥"
        exit 1
    fi

    # æ£€æŸ¥æ˜¯å¦éœ€è¦æ·»åŠ åŒ—äº¬æ•°æ®å’Œå¤–å–æ•°æ®
    log_info "æ£€æŸ¥æ˜¯å¦éœ€è¦æ·»åŠ é¢å¤–æ•°æ®..."

    # æ£€æŸ¥åŒ—äº¬æ•°æ®
    BEIJING_AFTER=$(python3 -c "
import sqlite3
try:
    conn = sqlite3.connect('stations.db')
    cursor = conn.cursor()
    cursor.execute('SELECT COUNT(*) FROM job_positions WHERE city = \"åŒ—äº¬\"')
    count = cursor.fetchone()[0]
    conn.close()
    print(count)
except:
    print(0)
" 2>/dev/null || echo "0")

    if [ "$BEIJING_AFTER" -eq 0 ] && [ -f "beijing_data_processing_v2.py" ]; then
        log_info "æ·»åŠ åŒ—äº¬å²—ä½æ•°æ®..."
        python beijing_data_processing_v2.py
    fi

    # æ£€æŸ¥å¤–å–æ•°æ®
    WAIMAI_AFTER=$(python3 -c "
import sqlite3
try:
    conn = sqlite3.connect('stations.db')
    cursor = conn.cursor()
    cursor.execute('SELECT COUNT(*) FROM job_positions WHERE job_type LIKE \"%å¤–å–%\"')
    count = cursor.fetchone()[0]
    conn.close()
    print(count)
except:
    print(0)
" 2>/dev/null || echo "0")

    if [ "$WAIMAI_AFTER" -eq 0 ] && [ -f "waimai_data_processing.py" ]; then
        log_info "æ·»åŠ å¤–å–å²—ä½æ•°æ®..."
        python waimai_data_processing.py

        # ä¿®æ­£å¤–å–å²—ä½ç±»åž‹
        python3 -c "
import sqlite3
conn = sqlite3.connect('stations.db')
cursor = conn.cursor()
cursor.execute('UPDATE job_positions SET job_type = \"ç¾Žå›¢å¤–å–éª‘æ‰‹\" WHERE job_type = \"ç¾Žå›¢å¤–å–\"')
conn.commit()
conn.close()
print('å·²ä¿®æ­£å¤–å–å²—ä½ç±»åž‹')
"
    fi

    deactivate  # é€€å‡ºè™šæ‹ŸçŽ¯å¢ƒ
    log_info "æœ¬åœ°æ•°æ®å¤„ç†å®Œæˆ âœ“"
}

# === æ­¥éª¤3ï¼šåˆ›å»ºç”Ÿäº§çŽ¯å¢ƒdocker-composeæ–‡ä»¶ ===
create_production_compose() {
    log_step "åˆ›å»ºç”Ÿäº§çŽ¯å¢ƒé…ç½®æ–‡ä»¶..."

    cat > "$COMPOSE_FILE" << EOF
version: '3.8'

services:
  gaode-station-service:
    image: ${IMAGE_NAME}:${IMAGE_TAG}
    ports:
      - "17263:17263"
      - "5000:5000"
    restart: unless-stopped
    container_name: gaode-station-service
    volumes:
      - ./stations.db:/app/stations.db
      - ./å²—ä½å±žæ€§.csv:/app/å²—ä½å±žæ€§.csv
      - ./å²—ä½ä½ç½®ä¿¡æ¯åº•è¡¨_with_coords.csv:/app/å²—ä½ä½ç½®ä¿¡æ¯åº•è¡¨_with_coords.csv
    environment:
      - FASTMCP_HOST=0.0.0.0
      - FASTMCP_PORT=17263
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000/"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
EOF

    log_info "ç”Ÿäº§çŽ¯å¢ƒé…ç½®æ–‡ä»¶åˆ›å»ºå®Œæˆ âœ“"
}

# === æ­¥éª¤4ï¼šæœ¬åœ°æž„å»ºDockeré•œåƒ ===
build_docker_image() {
    log_step "å¼€å§‹æž„å»ºDockeré•œåƒ..."

    log_info "æ­£åœ¨æž„å»ºé•œåƒ ${IMAGE_NAME}:${IMAGE_TAG}..."

    # æž„å»ºé•œåƒï¼ˆæŒ‡å®šx86æž¶æž„ï¼‰
    if ! docker build --platform linux/amd64 -t "${IMAGE_NAME}:${IMAGE_TAG}" .; then
        log_error "Dockeré•œåƒæž„å»ºå¤±è´¥"
        exit 1
    fi

    log_info "Dockeré•œåƒæž„å»ºå®Œæˆ âœ“"

    # æ˜¾ç¤ºé•œåƒä¿¡æ¯
    docker images "${IMAGE_NAME}:${IMAGE_TAG}"
}

# === æ­¥éª¤5ï¼šä¿å­˜é•œåƒä¸ºtaræ–‡ä»¶ ===
save_docker_image() {
    log_step "ä¿å­˜Dockeré•œåƒ..."

    # åˆ é™¤æ—§çš„é•œåƒæ–‡ä»¶
    if [ -f "$IMAGE_TAR" ]; then
        rm "$IMAGE_TAR"
    fi

    log_info "æ­£åœ¨ä¿å­˜é•œåƒä¸º $IMAGE_TAR..."
    if ! docker save "${IMAGE_NAME}:${IMAGE_TAG}" -o "$IMAGE_TAR"; then
        log_error "é•œåƒä¿å­˜å¤±è´¥"
        exit 1
    fi

    # æ˜¾ç¤ºæ–‡ä»¶å¤§å°
    IMAGE_SIZE=$(du -h "$IMAGE_TAR" | cut -f1)
    log_info "é•œåƒä¿å­˜å®Œæˆ âœ“ (å¤§å°: $IMAGE_SIZE)"
}

# === æ­¥éª¤6ï¼šç”Ÿæˆæž„å»ºä¿¡æ¯ ===
generate_build_info() {
    log_step "ç”Ÿæˆæž„å»ºä¿¡æ¯..."

    # èŽ·å–é•œåƒä¿¡æ¯
    IMAGE_ID=$(docker images --format "{{.ID}}" "${IMAGE_NAME}:${IMAGE_TAG}")
    BUILD_TIME=$(date "+%Y-%m-%d %H:%M:%S")
    IMAGE_SIZE=$(du -h "$IMAGE_TAR" | cut -f1)

    # ç”Ÿæˆæž„å»ºä¿¡æ¯JSON
    cat > "$BUILD_INFO_FILE" << EOF
{
  "image_name": "${IMAGE_NAME}",
  "image_tag": "${IMAGE_TAG}",
  "image_id": "${IMAGE_ID}",
  "image_tar": "${IMAGE_TAR}",
  "compose_file": "${COMPOSE_FILE}",
  "build_time": "${BUILD_TIME}",
  "image_size": "${IMAGE_SIZE}",
  "data_files": [
    "stations.db",
    "å²—ä½å±žæ€§.csv",
    "å²—ä½ä½ç½®ä¿¡æ¯åº•è¡¨_with_coords.csv"
  ]
}
EOF

    log_info "æž„å»ºä¿¡æ¯å·²ä¿å­˜åˆ° $BUILD_INFO_FILE"
}

# === ä¸»å‡½æ•° ===
main() {
    echo "========================================"
    echo "  é«˜å¾·åœ°å›¾æœåŠ¡ç«™ç‚¹æŸ¥è¯¢å·¥å…·"
    echo "  æœ¬åœ°æž„å»ºè„šæœ¬ v2.0"
    echo "========================================"
    echo ""

    log_info "å¼€å§‹æ‰§è¡Œæœ¬åœ°æž„å»º..."

    check_local_environment
    echo ""

    process_local_data
    echo ""

    create_production_compose
    echo ""

    build_docker_image
    echo ""

    save_docker_image
    echo ""

    generate_build_info
    echo ""

    echo "========================================"
    log_info "ðŸŽ‰ æœ¬åœ°æž„å»ºå®Œæˆï¼"
    echo ""
    log_info "æž„å»ºäº§ç‰©ï¼š"
    log_info "  - Dockeré•œåƒ: ${IMAGE_NAME}:${IMAGE_TAG}"
    log_info "  - é•œåƒæ–‡ä»¶: $IMAGE_TAR"
    log_info "  - é…ç½®æ–‡ä»¶: $COMPOSE_FILE"
    log_info "  - æž„å»ºä¿¡æ¯: $BUILD_INFO_FILE"
    log_info "  - æ•°æ®åº“æ–‡ä»¶: stations.db"
    echo ""
    log_info "ä¸‹ä¸€æ­¥: è¿è¡Œ './remote_deploy.sh' è¿›è¡Œè¿œç¨‹éƒ¨ç½²"
    echo "========================================"
}

# æ‰§è¡Œä¸»å‡½æ•°
main "$@"
